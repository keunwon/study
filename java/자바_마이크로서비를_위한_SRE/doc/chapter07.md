# 7. 트래픽 관리

## 7.1. 잠재적 장애 요소가 많은 마이크로서비스
- 마이크로서비스가 사용자와 주고받는 상호작용이 늘어날수록 저가용성 인스턴스가 발생할 가능성은 높아짐
- 다운스트림 서비스에 부하가 가중되면 서비스가 중단될 위험에 처함
- 호출 복원 패턴
	- 다운스트림 서비스에 부정적 영향을 미치는 방식으로 서비스를 보함
	- 최종 사용자에게 제공되는 서비스는 축소되지만 그 덕분에 서비스는 유지
## 7.2. 시스템의 동시성
- '동시성'이란 마이크로서비스가 한 번에 처리할 수 있는 요청 수를 의미
	- 일반적으로 모든 시스템은 태생적으로 동시 처리 능력에 한계가 있으며 CPU, 메모리 등의 리소스 정보를 통해 한계를 추산할 수 있음
- 한계를 벗어난 요청 시도는 즉각적으로 응답할 수 없으므로 대기열에 보관하거나 거부해야 함
## 7.3. 플랫폼 로드 밸런싱
- IaaS, CaaS, PAss 등 최신 런타임 플랫폼은 모두 기본적으로 클러스터 로드 밸런서를 제공
- 로드 밸런서는 주로 클러스터 인스턴에 트래픽을 분산하는 라운드 로빈 기능 등을 제공, 그 외의 다른 역할도 함께 수행
	- AWS 엘라스틱 로드 밸런서는 TLS 말단 처리, 콘텐츠 기반 라우팅, 고정 세션 등의 기능을 제공
	- 온프라미스 환경은 여전히 IIS, nginx, apache 등을 이용한 정적인 로드 밸런싱 기법이 널리 사용
## 7.4. 게이트웨이 로드 밸런싱
- 소프트웨어 기반 게이트웨이는 오픈 소스로 쉽게 구현할 수 있음 (스프링 클라우드 게이트웨이는 이 분야의 최신 기술이 집약)
- SRE 로드 밸런싱의 과제는 에러율이 높은 서버로부터 트래픽을 멀리 떨어뜨리는 것이지 응답 시간 단축이나 최적화가 아님
### 7.4.1. 최단 대기열 합류
- 라운드 로빈보다 위에 있는 가장 단순한 '적응형'로드 밸런서는 '최단 대기열 합류'
- 최단 대개열 합류 기법을 구현하려면 로드 밸런서의 시야에 있는 인스턴스들의 가용성 신호를 비교해야 함
- 로드 밸런서가 신규 요청을 수신하면 인플라이트 요청이 없는 인스턴스로 요청을 전달
	- 몇가지 최소/최대 통계만 있으면 대상 인스턴스를 선정할 수 있으므로 연산 비용이 저렴, 구현 편리
	- 로드밸런스가 2개 이상의 인스턴스로 존재하면 제대로 작동하지 않음
### 7.4.2. 인스턴스의 가용성 및 사용률
- 인스턴스가 측정한 가용성과 사용률을 로드 밸런서에 제출하면 모든 로드 밸런서가 인스턴스 상태 정보를 동일하게 공유할 수 있음
### 7.4.3. 헬스 체크
- 플랫폼 로드 밸런서가 '게이트웨이' 역할을 겸할 때가 있음 (AWS 로드 밸런서)
- 헬스 지표를 선정할 때는 애플리케이션의 가용성을 한 번에 보여주는 핵심 성능 지표를 찾아내어야 함
### 7.4.4. 양자택일
- 양자택일은 무작위로 두 서버를 선택하고 일부 기준 요건이 최대치가 되면 그중 하나를 선정하는 기법
### 7.4.5. 인스턴스 보호관찰
- 인스턴스가 구동될 떄 두 번째 워밍업 단계까지는 무리하게 사용률을 요청할 필요가 없음
- 신규 인스턴스를 향한 요청 수를 정적으로 제한하면 시규 인스턴스 과부하를 간단히 방지할 수 있음
## 7.5. 클라이언트 측 부하 분산
- 클라이언트 측 로브 밸런서 구현으로, 호출 주체가 로드 밸런싱 결정권을 갖음
- 원래는 유레카나 컨설 등에 구현된 서비스 디스커버리 메커니즘에서 서버 IP나 호스트명을 동적으로 가져오기 위해 사용
## 7.6. 헤지 요청
- 다운스트림 서비스나 리소스를 호출할 때 상위 1% 레이턴시가 미치는 악영향을 완화하는 전략 중 효능이 검증된 한 가지가 있음
- 여러 요청을 다운스트림으로 보낸 뒤 최초로 도착하는 응답만 수락하고 나머지는 반환함
- 일종의 헤지 요청을 추가로 보내는 기법
## 7.7. 호출 복원 패턴
- 모든 예측은 과거 성능 기반으로 수립
- 과거의 성능은 결코 미래의 결과를 보장해주지 않음 (실패에 대비한 복원 절차를 마련해야 함)
### 7.7.1. 재시도
- 다운스트림 서비스는 순간적인 장애를 자주 겪음 (쓰레드 풀 포화, 네트워크 접속 지연 인한 시간 초과 등), 이러한 요소는 단시간 내에 스스로 소멸함
- 호출자는 다운스트림 호출을 래핑해 재시도를 구현하고 일시적 오류에 대처해야 함
### 7.7.2. 비율 제한
- 갑자기 부하가 증가하면 리소스 부담이 가중되면 SLO 이하로 가용성이 낮아질 위험에 처함
- 비율 제한 기법을 도입하면 비록 제한된 처리량이나마 요청에 대응하도록 서비스를 지속시킬 수 있음
### 7.7.3. 벌크헤드
- 벌크헤드 패턴은 다운스트림 서비스를 서로 격리하고 각 서비스의 동시 처리 능력을 제한
	- B 서비스가 장애가 생겼을 때, B 서비스를 호출을 동반한 요청은 배제하고 그 외 요청은 A 서비스가 계속 응답할 수 있음
### 7.7.4. 서킷 브레이커
### 7.7.6. 호출 복원 패턴 선정
|패턴|제한 메커니즘|비고|
|:---|:---|:---|
|비율 제한|간격당 비율제한|순간적인 동시성에 제한을 두지 않음 (간격당 동시성이 한계치를 초과하면 제한)|
|벌크헤드|즉각적인 동시 처리 수준 제한|신규 요청이 발생하는 순간 동시성을 제한, 다운스트림 응답 시간에 영향을 미치며 요청 수를 직접적으로 제한하지 않음|
|서킷 브레이커|에러 대응형(일부는 다운스트림의 태생적 동시 처리 한계로 인해 발생)|RPC 요청 시간이 초과되거나 다운스트림 서비스가 HTTP 502(unavailiable)등의 오류로 응답, 다운 스트림이 포화되기 시작할 때를 제외하면 순간적 또는 간격당 처리 비율을 제한하지 않음|
### 7.7.7. 서비스 메시를 통한 구현
### 7.7.8. RSocket 구현
- RSocket은 리액티브 스트림의 의미 체계를 구현한 영속적 양방향 원격 프로시저 호출 프로토콜
- 장애를 대처할 수 없고 장애를 용납할 수도 없다면 컴포넌트는 상단의 컴포넌트들에 자신의 과부하 상태를 알려 부하를 줄이도록 해야 함
- 배압: 시스템이 부하를 버티고 정상적으로 응답하도록 유지시키는 핵심 피드백 매커니즘
- 네트워크 계층 전반에 배압 개념을 구현하면 애플리케이션 코드나 사이드카 프로세스에서 비율 제한, 벌크헤드, 서킷 브레이커의 필요성을 매우 효과적으로 배제할 수 있음
