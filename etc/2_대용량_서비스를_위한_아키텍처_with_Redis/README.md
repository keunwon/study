
## Chapter 1. 장애 포인트를 찾기 위한 모니터링
### 서비스에서의 지표
#### API CALL 수
- 현재 요청중인 초당 Call 수
- 실패한 CALL 수
#### API Latency
- 현재 API들의 속도가 Median 값, 99% 값, 최대값 등의 지표를 수집할 필요가 있음
### 서비스 노드 지표
- 서버의 상태
- CPU 사용량
- 메모리 사용량
- 디스크 사용량
- 네트워크 사용량
- 현재 동작중인 정상적인 서버의 수
### 에러의 수집
- Sentry 등의 외부 서비스 등도 많이 사용
### AWS에서 기본적인 지표들
- CloudWatch 사용
### Alarm
- 모니터링 지표가 특정 값을 넘는다면 슬랙이나 메신저 등으로 알람을 보내서 항상 특정 상황에 대한 알람이 필요
- Alarm에 등급을 나눠서 미리 전송
   - 장애의 정도: 서비스에 영향을 주는 것인지?
   - 행동의 여부: 즉각 조치가 필요한지?
### 테스트
- 성능테스트: 해당 서비스가 어느 정도의 성능을 내는지를 알아보는 테스트 (1000 TPS 등)
- 부하테스트: 어느 부분에서 어느 정보 부하가 걸리는 지를 알아보는 테스트
- 스트레스 테스트: 성능 테스트/부하테스트가 특정 시간 이상 지속적으로 안정적으로 되는지 확인하는 테스트
### 성능테스트 시에 주희할 점
- 주요 시나리오를 테스트는 하는지?
	- 단순히 API 하나만 호출하는 것이 아니라, 실제 서비스에서 사용되는 패턴으로 테스트가 필요
- 클라이언트의 성능 한계를 확인한다
	- 부하를 주는 클라이언트의 한계로 인해서 성능 측정이 어려울 수 있으므로, 클라이언트를 점점 늘리면서 테스트를 해야함
### 성능테스트 시에 확인할 부분
- OS에서 설정하는 값들에 대한 확인 필요
	- ulimit -a
		- Open Files
		- Max User Processes 라는 값의 튜닝이 필요함
	- /etc/limits.conf를 수정
### 성능테스트 툴
- Ngrinder
- Locust
- JMeter
- Gatling
- ab 

## Chapter2. 대규모 서비스 설계를 위한 백엔드 에센셜
### LoadBalancer
ri
- 사용자의 요청을 여러 서버로 분배해주는 하드웨어 or 소프트웨어 장비
### Server Side vs Client Side
- Server Side(Proxy LB)
	- Caller는 LB의 주소만 알고 LB 뒤의 상태는 알지 못함
	- 클라인트가 서버의 개별 주소를 알 필요가 없음 (로드 밸런서의 주소를 알아야 함)
	- 실제적으로 한 단계를 더 거치므로 Latency가 늘어날 수 있음 (Hop이라고 부름)
	- 로드밸런서에 장애를 발생하면 서비스가 동작하지 못함
- Client Side
	- 클라이언트가 서버의 대수 및 주소를 모두 알아야 함
	- Hop이 존재하지 않으므로 좀 더 빠른 Latency를 보여줌
	- 장애포인트가 줄어듬
	- 클라이언트에서 서버의 목록과 주소를 관리애햐 한다는 단점이 존재
### Service Discovery
- 서비스 디스커버리는 서비스나 거기에 속한 속한 서버 목록을 어떻게 찾을 것인가
- 서비스의 접속 방법을 알려주는 기능 (HTTP, TCP) 필요
- 서비스 내의 서버의 추가/제거가 있을 때 이를 알려주는 기능이 필요  
- 서비스 디스커버리 툴을 Cordinator라고 함 (Zookeeper)
#### Cordinator의 특징
- 서비스 가용성이 높음
	- 3대 이상으로 동작, 데이터 동기화 이루어짐
	- 절반 이상이 장애가 나지 않는 이상, 서비스의 유지가 가능
- 보통은 특정 값을 저장할 수 있는 대쉬보드의 역할을 함
- 노드의 순서를 보장
### Circuit Breaker
- Closed: 정상적인 API 호출이 되는 상태
- Open: 일정시간 동안 API 호출을 바로 실패하는 상태
- Half Open:
	- Open인 상태에서 일정 시간이 지나면 상태를 다시 확인하기 위해서 API 호출을 시도해보는 상태
	- Half Open 성공하면 Closed, 실패하면 다시 Open으로 이동
### Failover
- Active 한 시스테메에 장애가 발생했을 때 StandBy 서버가 Active로 전환해서 서비스가 계속 운영되게 하는 것을 말함
- 서비스 가용성 (High Availabilty) 제공하기 위해서 사용
#### VIP를 이용하는 방법
- 장애가 일어나면 VIP를 변경 
- 기존 서버의 커넥션을 끊는 작업이 필요
#### DNS를 이용하는 방법
- VIP를 이용하는 방법보다 구성이 쉬움
- 장애가 일어나면 DNS를 변경
- AWS에서 제공하는 Failover 방식
	- ELB의 Failover
	- ElastiCache의 Endpoint Failover
  - RDS의 Endpoint Failover   
- DNS를 이용한 방식에서 주의할 점
	- DNS는 TTL이 존재
		- DNS를 이용한 Failover는 DNS TTL을 짧게 설정
		- DNS 서버에 부하를 많이 줄 수 있음
### Replication
- Primary의 데이터를 Secondary에서 복사해서 데이터의 Sync를 맞추는 작업
- Replication이 안되면, 장애시 데이터의 유실이 많이 발생
### Sharding
#### Vertical Partitioning
- 하나의 Table을 컬럼 기준으로 나눔
- 자주 사용하는 컬럼과 자주 사용하지 않는 컬럼으로 나눠서 성능을 향상
#### Horizontal Partitioning
- 같은 Table을 데이터를 기준으로 나눔
- 데이터의 개수가 적어지므로 하나의 DB에서 처리해야 하는 부하가 줄어듬
- Horizontal Partitioning을 Sharding이라고 함
- 여러 대의 DB와 연결이 되어야 한다라는 단점이 있음
#### Sharding 이슈
- 데이터가 여러 대의 DB에 저장된다면, 어떤 데이터를 어디에 저장할 것인가를 알아야 함
#### Sharding Key 생성 규칙
- Range:특정 범위대역으로 나누기
	- 장점: 새로운 Shard를 추가하는 것이 다른 방식보다 쉬움
  - 단점: Shard 간의 데이터가 균등하지 못할 가능성이 높음
- Modular: 서대 대수로 나누기
	- 장점: 균등하게 분배
	- 단점: 
		- 1 대씩 서버 추가하면 데이터 이동이 심해짐
		- 1대 -> 2대 -> 4대 -> 8대 -> 16대 순으로 서버를 증가시켜야 함
- Indexed: 특정 데이터의 위치를 가리키는 서버가 존재
	- 장점: 데이터 분배를 원하는 형태로 하기 쉬움
  - 단점: Indexed 자체가 하나의 서비스가 되어야 함 
- Complexed
	- 여러 가지 형태를 섞은 형태
	- 구현이 복잡해짐
### Consistent Hashing
- 같은 Hash를 사용하면 항상 같은 결과를 보여줌
- Consistent Hashing은 장애에 안정적인가?
	- 서버의 추가/삭제 시에 리밸런싱은 적게 일어남
- Consistent Hasing은 부하에 안정적인가?
	- 서버 장애가 발생하면 해시 Ring의 다음 서버에 모든 부하를 넘김
- Consistent Hasing에서 서버의 이름을 Unique 한 Nickname을 사용해야 함 
### GUID
- 유일한 KEY (전체 유니크 key)
- 보통 8byte 정도의 크기로 사용 (64bit)
- 유일성, 시간(timestamp)으로 정렬 가능해야 함
### 비동기 큐 사용
- 무거운 작업의 처리 
- DB 작업이 아니더라도 속도가 오래 걸리는 작업을 비동기로 후처리 할 수 있음
- Worker 개수에 따라서 작업 처리량을 조절할 수 있음
- 비동기로 동작하므로 실제 DB 처리가 늦어지므로, 내가 쓴 데이터를 바로 볼 수 없을 수도 있음
	- 이를 위해 실제로 서비에서는 Cache에 먼저 저장해서 해당 결과를 서비스에서 볼 수 있도록 함 (Write-Back 형태를 취함)

### 배포
### 일반적인 무정지 배포 방법 (Rolling Update)
- LB에서 배포할 서버를 제외하고, 서버에 배포 이후 LB에 다시 추가
### Blue-Green 배포
1. 현재 Blue Set으로 서비스 중이라면, 같은 양의 Green을 준비해서 Green Set에 새로운 버전을 배포
2. Blue Set을 바라보는 설정을 Green을 바라보도록 수정
3. Blue Set을 제거
### Blue-Green 쉬운가?
- 같은 수의 장비를 쉽게 준비할 수 있을까?
	- Cloud라면 손쉬움
### On-Premis에 Blue-Green 도입
- 사용하는 리소스의 제한이 필요 (cpu, memory 절반)
- 한 서버에 두 개의 프로세스와 Proxy를 실행
- 장점: 새로운 장비의 수급없이 빠른 배포가 가능
- 단점: 리소스를 풀로 사용하지 못하므로, 부하가 많은 상황에서 배포 시 장애가 발생할 수 있음
### Canary Deployment
- 몇 대만 배포를 해서 장애를 살펴봄
- 어떻게 특정 유저들은 특정 서버로 고정할 수 있을까?
	- tag를 추가하여 redirect 
